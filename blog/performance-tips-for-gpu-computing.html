<!DOCTYPE html><html lang="en"><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>References for GPU computeing (2)</title><meta name="og:description" content="個人的な NVIDIA GPU ポインタ集 : Performance Tips"/><meta name="og:title" content="References for GPU computeing (2)"/><meta property="og:image" content="https://avatars0.githubusercontent.com/u/1871262?s=400"/><meta name="twitter:site" content="@denkiwakame"/><meta name="twitter:creator" content="@denkiwakame"/><meta name="twitter:card" content="summary"/><meta name="twitter:url" content="https://denkiwakame.github.io"/><link rel="icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text y=%22.9em%22 font-size=%2290%22&gt;⚡️&lt;/text&gt;&lt;/svg&gt;"/><meta name="next-head-count" content="11"/><link rel="preload" href="/_next/static/css/f6eb9f594942525c6a31.css" as="style"/><link rel="stylesheet" href="/_next/static/css/f6eb9f594942525c6a31.css" data-n-g=""/><link rel="preload" href="/_next/static/css/42954c53b05ccf0b2cdd.css" as="style"/><link rel="stylesheet" href="/_next/static/css/42954c53b05ccf0b2cdd.css" data-n-p=""/><noscript data-n-css=""></noscript><link rel="preload" href="/_next/static/chunks/webpack-acbe2a1d0483950086ba.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.3e0dfad0cbf263c0c4a9.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.3f227e1c895e39cb7779.js" as="script"/><link rel="preload" href="/_next/static/chunks/main-deac83b1f9d78151fc4a.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-6179aa4185a808d7a1de.js" as="script"/><link rel="preload" href="/_next/static/chunks/cb1608f2.7455795c198376a5d1d3.js" as="script"/><link rel="preload" href="/_next/static/chunks/6bd6ae6efdef6db205175312548a04e035b50d59.9002859aca81683f8631.js" as="script"/><link rel="preload" href="/_next/static/chunks/bfa37fcd0818edd0d3354ea585e5d4d4b3e87fa4.54a90d76d8498c0c7409.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/blog/%5Bslug%5D-86baed40f497662539f5.js" as="script"/></head><body><div id="__next"><header class="header_header__WP9pK"><ul><li><a href="/">ABOUT</a></li><li><a href="/blog">BLOG</a></li></ul></header><div class="blog_post__39rqQ"><h1>References for GPU computeing (2)</h1><div class="blog_posted__2Ypb5">Posted: <!-- -->January 08, 2021</div><div class="blog_snsShare__25gZO"><button aria-label="twitter" class="react-share__ShareButton blog_snsShareButton__1wTB-" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 64 64" width="24" height="24"><rect width="64" height="64" rx="0" ry="0" fill="#00aced"></rect><path d="M48,22.1c-1.2,0.5-2.4,0.9-3.8,1c1.4-0.8,2.4-2.1,2.9-3.6c-1.3,0.8-2.7,1.3-4.2,1.6 C41.7,19.8,40,19,38.2,19c-3.6,0-6.6,2.9-6.6,6.6c0,0.5,0.1,1,0.2,1.5c-5.5-0.3-10.3-2.9-13.5-6.9c-0.6,1-0.9,2.1-0.9,3.3 c0,2.3,1.2,4.3,2.9,5.5c-1.1,0-2.1-0.3-3-0.8c0,0,0,0.1,0,0.1c0,3.2,2.3,5.8,5.3,6.4c-0.6,0.1-1.1,0.2-1.7,0.2c-0.4,0-0.8,0-1.2-0.1 c0.8,2.6,3.3,4.5,6.1,4.6c-2.2,1.8-5.1,2.8-8.2,2.8c-0.5,0-1.1,0-1.6-0.1c2.9,1.9,6.4,2.9,10.1,2.9c12.1,0,18.7-10,18.7-18.7 c0-0.3,0-0.6,0-0.8C46,24.5,47.1,23.4,48,22.1z" fill="white"></path></svg></button></div><div class="blog_snsShare__25gZO"><button title="References for GPU computeing (2)" aria-label="facebook" class="react-share__ShareButton blog_snsShareButton__1wTB-" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 64 64" width="24" height="24"><rect width="64" height="64" rx="0" ry="0" fill="#3b5998"></rect><path d="M34.1,47V33.3h4.6l0.7-5.3h-5.3v-3.4c0-1.5,0.4-2.6,2.6-2.6l2.8,0v-4.8c-0.5-0.1-2.2-0.2-4.1-0.2 c-4.1,0-6.9,2.5-6.9,7V28H24v5.3h4.6V47H34.1z" fill="white"></path></svg></button></div><div class="blog_snsShare__25gZO"><button aria-label="hatena" class="react-share__ShareButton blog_snsShareButton__1wTB-" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 64 64" width="24" height="24"><rect width="64" height="64" rx="0" ry="0" fill="#009ad9"></rect><path d="M 36.164062 33.554688 C 34.988281 32.234375 33.347656 31.5 31.253906 31.34375 C 33.125 30.835938 34.476562 30.09375 35.335938 29.09375 C 36.191406 28.09375 36.609375 26.78125 36.609375 25.101562 C 36.628906 23.875 36.332031 22.660156 35.75 21.578125 C 35.160156 20.558594 34.292969 19.71875 33.253906 19.160156 C 32.304688 18.640625 31.175781 18.265625 29.847656 18.042969 C 28.523438 17.824219 26.195312 17.730469 22.867188 17.730469 L 14.769531 17.730469 L 14.769531 47.269531 L 23.113281 47.269531 C 26.46875 47.269531 28.886719 47.15625 30.367188 46.929688 C 31.851562 46.695312 33.085938 46.304688 34.085938 45.773438 C 35.289062 45.148438 36.28125 44.179688 36.933594 42.992188 C 37.597656 41.796875 37.933594 40.402344 37.933594 38.816406 C 37.933594 36.621094 37.347656 34.867188 36.164062 33.554688 Z M 22.257812 24.269531 L 23.984375 24.269531 C 25.988281 24.269531 27.332031 24.496094 28.015625 24.945312 C 28.703125 25.402344 29.042969 26.183594 29.042969 27.285156 C 29.042969 28.390625 28.664062 29.105469 27.9375 29.550781 C 27.210938 29.992188 25.84375 30.199219 23.855469 30.199219 L 22.257812 30.199219 Z M 29.121094 41.210938 C 28.328125 41.691406 26.976562 41.925781 25.078125 41.925781 L 22.257812 41.925781 L 22.257812 35.488281 L 25.195312 35.488281 C 27.144531 35.488281 28.496094 35.738281 29.210938 36.230469 C 29.925781 36.726562 30.304688 37.582031 30.304688 38.832031 C 30.304688 40.078125 29.914062 40.742188 29.105469 41.222656 Z M 29.121094 41.210938 M 46.488281 39.792969 C 44.421875 39.792969 42.742188 41.46875 42.742188 43.535156 C 42.742188 45.605469 44.421875 47.28125 46.488281 47.28125 C 48.554688 47.28125 50.230469 45.605469 50.230469 43.535156 C 50.230469 41.46875 48.554688 39.792969 46.488281 39.792969 Z M 46.488281 39.792969 M 43.238281 17.730469 L 49.738281 17.730469 L 49.738281 37.429688 L 43.238281 37.429688 Z M 43.238281 17.730469 " fill="white"></path></svg></button></div><hr/><p>個人的な NVIDIA GPU ポインタ集 : Performance Tips</p><p><a href="https://denkiwakame.github.io/blog/references-for-gpu-computing" rel="noopener" target="_blank">前記事</a> の続き.</p><a href="#profiling" id="profiling" style="color:inherit"><h2>Profiling</h2></a><p>そもそもプログラムが何で律速しているのかを知らなければ意味がない.</p><p> CPUネックなのか？GPUネックなのか？CPU-GPU間の通信ネックなのか？ GPUネックだとして、メモリ帯域で律速しているのか？演算器で律速しているのか？レイテンシが問題なのか？</p><div style="background:var(--bg-2);padding:1em;margin-top:.5em;border-radius:var(--radius);font-family:var(--font-mono)"><a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html" target="_blank" style="color:var(--accents-1);font-size:0.8rem;font-weight:bolder">Profiler :: CUDA Toolkit Documentation</a><div style="font-size:0.6rem">The user manual for NVIDIA profiling tools for optimizing performance of CUDA applications. This document describes NVIDIA profiling tools that enable you to understand and optimize the performance of your CUDA, OpenACC or OpenMP applications.</div><div style="margin-top:0.4rem;font-size:0.6rem;font-weight:bolder"></div></div><p><code>NSight Systems</code> に移行しなければならない気持ちはあるが未だに <code>nvprof / nvvp</code>を使っている.</p><p>単純に転送速度 / kernel 毎の速度ぐらいが知りたければ <code>nvprof</code> を、メモリ帯域や演算資源の使用率グラフまで知りたければ <code>nvvp</code> を使う.</p><div style="background:var(--bg-2);padding:1em;margin-top:.5em;border-radius:var(--radius);font-family:var(--font-mono)"><a href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvtx" target="_blank" style="color:var(--accents-1);font-size:0.8rem;font-weight:bolder">Profiler :: CUDA Toolkit Documentation</a><div style="font-size:0.6rem">The user manual for NVIDIA profiling tools for optimizing performance of CUDA applications. This document describes NVIDIA profiling tools that enable you to understand and optimize the performance of your CUDA, OpenACC or OpenMP applications.</div><div style="margin-top:0.4rem;font-size:0.6rem;font-weight:bolder"></div></div><p>NVTX annotation を利用するとプロファイル結果を独自のセグメントで見やすくできる.</p><p>DL用途の場合は以下を参考にした方がより実践的で</p><div style="background:var(--bg-2);padding:1em;margin-top:.5em;border-radius:var(--radius);font-family:var(--font-mono)"><a href="https://qiita.com/shu65/items/42914bd2ad01d1e323da" target="_blank" style="color:var(--accents-1);font-size:0.8rem;font-weight:bolder">Chainer/ChainerMNのおすすめなプロファイルの取り方＆プロファイルの見方の注意点 - Qiita</a><div style="font-size:0.6rem">自分への備忘録的な意味も込めて最近まとめたので、私が実践しているChainer/ChainerMNのプロファイルの取り方とプロファイル結果の見方を紹介します。 この記事で使うプロファイラは、Chainerのプロファイルを取る際まず取るべきと思われるcProfileとnvprofの二つです。 この記事ではChainerMNのmnistのサンプルをベースに改造したコードで説明を行っています。 ...</div><div style="margin-top:0.4rem;font-size:0.6rem;font-weight:bolder"></div></div><p>厳密なプロファイル結果を必要としないのであれば、<code>torch.utils.bottleneck</code> のようなDLFW組み込みの簡易プロファイラで事足りるユーザが多いかもしれない.</p><div style="background:var(--bg-2);padding:1em;margin-top:.5em;border-radius:var(--radius);font-family:var(--font-mono)"><a href="https://pytorch.org/docs/stable/bottleneck.html" target="_blank" style="color:var(--accents-1);font-size:0.8rem;font-weight:bolder">torch.utils.bottleneck - PyTorch 1.7.0 documentation</a><div style="font-size:0.6rem">torch.utils.bottleneck is a tool that can be used as an initial step for debugging bottlenecks in your program. It summarizes runs of your script with the Python profiler and PyTorch&#x27;s autograd profiler. Run it on the command line with where [args] are any number of arguments to script.py, or run for more usage instructions.</div><div style="margin-top:0.4rem;font-size:0.6rem;font-weight:bolder"></div></div><p>NVIDIA からは 一連の DL用途の profiler metrics をラップした DLProf がリリースされている（が Tensor Core Usage 等は nvprof からも取れる）</p><div style="background:var(--bg-2);padding:1em;margin-top:.5em;border-radius:var(--radius);font-family:var(--font-mono)"><a href="https://docs.nvidia.com/deeplearning/frameworks/dlprof-user-guide/" target="_blank" style="color:var(--accents-1);font-size:0.8rem;font-weight:bolder">DLProf User Guide :: NVIDIA Deep Learning Frameworks Documentation</a><div style="font-size:0.6rem">The Deep Learning Profiler (DLProf) User Guide provides instructions on using the DLProf tool to improve the performance of deep learning models. Deep Learning Profiler is a tool for profiling deep learning models to help data scientists understand and improve performance of their models visually via Tensorboard or by analyzing text reports.</div><div style="margin-top:0.4rem;font-size:0.6rem;font-weight:bolder"></div></div><a href="#performance-tips-(cuda)" id="performance-tips-(cuda)" style="color:inherit"><h2>Performance Tips (CUDA)</h2></a><p>以下に Performance Guide があるがはGPU玄人以外には難しいので最初は <a href="https://book.impress.co.jp/books/1115101001" rel="noopener" target="_blank">CUDA C プロフェッショナルプログラミング</a> を読むと良い.</p><div style="background:var(--bg-2);padding:1em;margin-top:.5em;border-radius:var(--radius);font-family:var(--font-mono)"><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#performance-guidelines" target="_blank" style="color:var(--accents-1);font-size:0.8rem;font-weight:bolder">Programming Guide :: CUDA Toolkit Documentation</a><div style="font-size:0.6rem">Figure 2. GPU Computing Applications. CUDA is designed to support various languages and application programming interfaces. Figure 3. Automatic Scalability Note: A GPU is built around an array of Streaming Multiprocessors (SMs) (see Hardware Implementation for more details).</div><div style="margin-top:0.4rem;font-size:0.6rem;font-weight:bolder"></div></div><p>チューニングに対する基本的な考え方がまとまっている. </p><p>プロファイル結果に応じて 1) 演算資源で律速している場合は GPU の SIMDで1命令で捌けないか、アルゴリズムの工夫で計算量が落ちないかを検討し、2) メモリ帯域で律速している場合 はメモリアクセス方法の改善や高速な（L1/sharedmem/register）メモリでの代替を検討する. </p><div style="background:var(--bg-2);padding:1em;margin-top:.5em;border-radius:var(--radius);font-family:var(--font-mono)"><a href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html" target="_blank" style="color:var(--accents-1);font-size:0.8rem;font-weight:bolder">Best Practices Guide :: CUDA Toolkit Documentation</a><div style="font-size:0.6rem">The programming guide to using the CUDA Toolkit to obtain the best performance from NVIDIA GPUs.</div><div style="margin-top:0.4rem;font-size:0.6rem;font-weight:bolder"></div></div><p>アーキテクチャごとの tuning guide は以下にまとまっている.</p><div style="background:var(--bg-2);padding:1em;margin-top:.5em;border-radius:var(--radius);font-family:var(--font-mono)"><a href="https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html#tuning-cuda-applications-for-ampere" target="_blank" style="color:var(--accents-1);font-size:0.8rem;font-weight:bolder">NVIDIA Ampere GPU Architecture Tuning Guide :: CUDA Toolkit Documentation</a><div style="font-size:0.6rem">The NVIDIA A100 GPU based on compute capability 8.0 increases the maximum capacity of the combined L1 cache, texture cache and shared memory to 192 KB, 50% larger than the L1 cache in NVIDIA V100 GPU. The combined L1 cache capacity for GPUs with compute capability 8.6 is 128 KB.</div><div style="margin-top:0.4rem;font-size:0.6rem;font-weight:bolder"></div></div><p>developer blog の pro tips は特定のアルゴリズムについて実践的なテクニックが紹介され、たまに更新されている</p><div style="background:var(--bg-2);padding:1em;margin-top:.5em;border-radius:var(--radius);font-family:var(--font-mono)"><a href="https://developer.nvidia.com/blog/tag/pro-tip/" target="_blank" style="color:var(--accents-1);font-size:0.8rem;font-weight:bolder">Tag: Pro Tip | NVIDIA Developer Blog</a><div style="font-size:0.6rem"></div><div style="margin-top:0.4rem;font-size:0.6rem;font-weight:bolder"></div></div><a href="#performance-tips-(deep-learning)" id="performance-tips-(deep-learning)" style="color:inherit"><h2>Performance Tips (Deep Learning)</h2></a><a href="#automated-mixed-precision-training-(amp)" id="automated-mixed-precision-training-(amp)" style="color:inherit"><h3>Automated Mixed Precision Training (AMP)</h3></a><p>ECCV&#x27;20 での tutorial が現存する資料で最も優れている.</p><div style="background:var(--bg-2);padding:1em;margin-top:.5em;border-radius:var(--radius);font-family:var(--font-mono)"><a href="https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/" target="_blank" style="color:var(--accents-1);font-size:0.8rem;font-weight:bolder">AMP tutorial</a><div style="font-size:0.6rem">This tutorial will describe techniques that utilize half-precision floating point representations to allow deep learning practitioners to accelerate the training of large deep networks while also reducing memory requirements.</div><div style="margin-top:0.4rem;font-size:0.6rem;font-weight:bolder"></div></div><a href="#training-neural-networks-with-tensor-cores" id="training-neural-networks-with-tensor-cores" style="color:inherit"><h3>Training Neural Networks with Tensor Cores</h3></a><div style="padding-top:56%;position:relative" class="asset-wrapper"><iframe style="width:100%;height:100%;border:none;position:absolute;top:0" src="https://www.youtube.com/embed/jF4-_ZK_tyc?feature=oembed"></iframe></div><a href="#pytorch-performance-tips" id="pytorch-performance-tips" style="color:inherit"><h3>PyTorch Performance Tips</h3></a><div style="padding-top:56%;position:relative" class="asset-wrapper"><iframe style="width:100%;height:100%;border:none;position:absolute;top:0" src="https://www.youtube.com/embed/9mS1fIYj1So?feature=oembed"></iframe></div><p><a href="https://developer.nvidia.com/blog/tag/pro-tip/" rel="noopener" target="_blank">https://developer.nvidia.com/blog/tag/pro-tip/</a></p><a href="#to-be-continued-..." id="to-be-continued-..." style="color:inherit"><h2>TO BE CONTINUED ...</h2></a><p>未定</p></div><footer><span>© 2020 Mai Nishimura powered by<!-- --> <a href="https://github.com/ijjk/notion-blog" target="_blank">Notion Blog</a></span></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"id":"ceb89529-935e-4c2b-bf1f-044b7308524e","Published":"Yes","Authors":["Mai Nishimura"],"Slug":"performance-tips-for-gpu-computing","Date":1610064000856,"Page":"References for GPU computeing (2)","preview":[[["個人的な NVIDIA GPU ポインタ集 : Performance Tips"]]],"content":[{"role":"editor","value":{"id":"4103caf2-fe84-4200-8128-6bd91c8d059d","version":43,"type":"text","properties":{"title":[["個人的な NVIDIA GPU ポインタ集 : Performance Tips"]]},"created_time":1610188500000,"last_edited_time":1610188500000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"74039037-3dbd-448b-8319-0b8cbf47241b","version":4,"type":"divider","format":{"copied_from_pointer":{"id":"b08cb770-6d40-46b4-a673-31ada900aecf","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188504248,"last_edited_time":1610188500000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"b08cb770-6d40-46b4-a673-31ada900aecf","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"351d1ed9-4e4c-4b28-b2e7-6777bc218039","version":44,"type":"text","properties":{"title":[["前記事",[["a","https://denkiwakame.github.io/blog/references-for-gpu-computing"]]],[" の続き."]]},"created_time":1610189160000,"last_edited_time":1610189220000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"82c8104f-ee13-435a-95d8-d396b8f81197","version":4,"type":"sub_header","properties":{"title":[["Profiling"]]},"format":{"copied_from_pointer":{"id":"66444a10-de79-468e-817d-c666d4146e94","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480065,"last_edited_time":1610189160000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"66444a10-de79-468e-817d-c666d4146e94","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"e860e39d-5ba1-46f3-b246-f0a9d1676463","version":4,"type":"text","properties":{"title":[["そもそもプログラムが何で律速しているのかを知らなければ意味がない."]]},"format":{"copied_from_pointer":{"id":"bca3d483-541f-4b07-b7c8-822f659c28f5","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480066,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"bca3d483-541f-4b07-b7c8-822f659c28f5","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"d275d1e2-4299-43c4-b46b-cbcfded26feb","version":4,"type":"text","properties":{"title":[[" CPUネックなのか？GPUネックなのか？CPU-GPU間の通信ネックなのか？ GPUネックだとして、メモリ帯域で律速しているのか？演算器で律速しているのか？レイテンシが問題なのか？"]]},"format":{"copied_from_pointer":{"id":"420cbf0c-dec1-4ebc-92ce-541e57dc5ba3","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480067,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"420cbf0c-dec1-4ebc-92ce-541e57dc5ba3","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"ee1c81be-579e-4ae1-880b-d9249f32e0e6","version":4,"type":"bookmark","properties":{"link":[["https://docs.nvidia.com/cuda/profiler-users-guide/index.html"]],"title":[["Profiler :: CUDA Toolkit Documentation"]],"description":[["The user manual for NVIDIA profiling tools for optimizing performance of CUDA applications. This document describes NVIDIA profiling tools that enable you to understand and optimize the performance of your CUDA, OpenACC or OpenMP applications."]]},"format":{"bookmark_cover":"https://docs.nvidia.com/cuda/profiler-users-guide/graphics/highlight-exec-dependencies.png","copied_from_pointer":{"id":"4a830c3c-d10e-48d6-9508-0bd86c8bc319","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480069,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"4a830c3c-d10e-48d6-9508-0bd86c8bc319","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"b5e09578-4b1b-4ddc-9cf2-36e8c605a51e","version":4,"type":"text","properties":{"title":[["NSight Systems",[["c"]]],[" に移行しなければならない気持ちはあるが未だに "],["nvprof / nvvp",[["c"]]],["を使っている."]]},"format":{"copied_from_pointer":{"id":"263dd003-4d9f-43c5-8e44-7d00a110aa1a","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480072,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"263dd003-4d9f-43c5-8e44-7d00a110aa1a","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"ad3a8c8c-9d60-4442-9261-c16902be11cf","version":4,"type":"text","properties":{"title":[["単純に転送速度 / kernel 毎の速度ぐらいが知りたければ "],["nvprof",[["c"]]],[" を、メモリ帯域や演算資源の使用率グラフまで知りたければ "],["nvvp",[["c"]]],[" を使う."]]},"format":{"copied_from_pointer":{"id":"febcedd9-1dbb-4c03-97ce-29976154c32b","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480074,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"febcedd9-1dbb-4c03-97ce-29976154c32b","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"3aa98c3c-e57c-4e96-98f4-d15243fb07aa","version":4,"type":"bookmark","properties":{"link":[["https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvtx"]],"title":[["Profiler :: CUDA Toolkit Documentation"]],"description":[["The user manual for NVIDIA profiling tools for optimizing performance of CUDA applications. This document describes NVIDIA profiling tools that enable you to understand and optimize the performance of your CUDA, OpenACC or OpenMP applications."]]},"format":{"bookmark_cover":"https://docs.nvidia.com/cuda/profiler-users-guide/graphics/highlight-exec-dependencies.png","copied_from_pointer":{"id":"375d790f-3f9d-4e81-9f72-a867573873ee","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480075,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"375d790f-3f9d-4e81-9f72-a867573873ee","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"8ad19a87-3b8e-43ba-90cb-0537111faa0e","version":4,"type":"text","properties":{"title":[["NVTX annotation を利用するとプロファイル結果を独自のセグメントで見やすくできる."]]},"format":{"copied_from_pointer":{"id":"c105ad9b-62df-4ea5-8428-b35543af0d36","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480076,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"c105ad9b-62df-4ea5-8428-b35543af0d36","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"c7d45f6d-e52a-47d9-88fc-e2dcda50188c","version":4,"type":"text","properties":{"title":[["DL用途の場合は以下を参考にした方がより実践的で"]]},"format":{"copied_from_pointer":{"id":"40db7a1c-19e6-478e-816d-46158133d161","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480077,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"40db7a1c-19e6-478e-816d-46158133d161","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"064f017b-6c91-47f0-afac-76e9b866399f","version":4,"type":"bookmark","properties":{"link":[["https://qiita.com/shu65/items/42914bd2ad01d1e323da"]],"title":[["Chainer/ChainerMNのおすすめなプロファイルの取り方＆プロファイルの見方の注意点 - Qiita"]],"description":[["自分への備忘録的な意味も込めて最近まとめたので、私が実践しているChainer/ChainerMNのプロファイルの取り方とプロファイル結果の見方を紹介します。 この記事で使うプロファイラは、Chainerのプロファイルを取る際まず取るべきと思われるcProfileとnvprofの二つです。 この記事ではChainerMNのmnistのサンプルをベースに改造したコードで説明を行っています。 ..."]]},"format":{"bookmark_icon":"https://cdn.qiita.com/assets/favicons/public/production-c620d3e403342b1022967ba5e3db1aaa.ico","bookmark_cover":"https://qiita-user-contents.imgix.net/https%3A%2F%2Fcdn.qiita.com%2Fassets%2Fpublic%2Farticle-ogp-background-1150d8b18a7c15795b701a55ae908f94.png?ixlib=rb-1.2.2\u0026w=1200\u0026mark=https%3A%2F%2Fqiita-user-contents.imgix.net%2F~text%3Fixlib%3Drb-1.2.2%26w%3D840%26h%3D380%26txt%3DChainer%252FChainerMN%25E3%2581%25AE%25E3%2581%258A%25E3%2581%2599%25E3%2581%2599%25E3%2582%2581%25E3%2581%25AA%25E3%2583%2597%25E3%2583%25AD%25E3%2583%2595%25E3%2582%25A1%25E3%2582%25A4%25E3%2583%25AB%25E3%2581%25AE%25E5%258F%2596%25E3%2582%258A%25E6%2596%25B9%25EF%25BC%2586%25E3%2583%2597%25E3%2583%25AD%25E3%2583%2595%25E3%2582%25A1%25E3%2582%25A4%25E3%2583%25AB%25E3%2581%25AE%25E8%25A6%258B%25E6%2596%25B9%25E3%2581%25AE%25E6%25B3%25A8%25E6%2584%258F%25E7%2582%25B9%26txt-color%3D%2523333%26txt-font%3DHiragino%2520Sans%2520W6%26txt-size%3D54%26txt-clip%3Dellipsis%26txt-align%3Dcenter%252Cmiddle%26s%3D6f779ac4413903f4cdca1f513a32edf8\u0026mark-align=center%2Cmiddle\u0026blend=https%3A%2F%2Fqiita-user-contents.imgix.net%2F~text%3Fixlib%3Drb-1.2.2%26w%3D840%26h%3D500%26txt%3D%2540shu65%26txt-color%3D%2523333%26txt-font%3DHiragino%2520Sans%2520W6%26txt-size%3D45%26txt-align%3Dright%252Cbottom%26s%3D9e945d5c5bb6b4706692bbb12898a0d5\u0026blend-align=center%2Cmiddle\u0026blend-mode=normal\u0026s=0b7132c2b90182a3267e959f0278dfe8","copied_from_pointer":{"id":"da18571e-0af4-4f90-b560-76c752326506","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480078,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"da18571e-0af4-4f90-b560-76c752326506","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"fcf16b63-3c4b-4d44-b547-7433d6f09f43","version":124,"type":"text","properties":{"title":[["厳密なプロファイル結果を必要としないのであれば、"],["torch.utils.bottleneck",[["c"]]],[" のようなDLFW組み込みの簡易プロファイラで事足りるユーザが多いかもしれない."]]},"created_time":1610188800000,"last_edited_time":1610188860000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"a0899352-4a5b-4e97-88a9-0933c7c62fd3","version":4,"type":"bookmark","properties":{"link":[["https://pytorch.org/docs/stable/bottleneck.html"]],"title":[["torch.utils.bottleneck - PyTorch 1.7.0 documentation"]],"description":[["torch.utils.bottleneck is a tool that can be used as an initial step for debugging bottlenecks in your program. It summarizes runs of your script with the Python profiler and PyTorch's autograd profiler. Run it on the command line with where [args] are any number of arguments to script.py, or run for more usage instructions."]]},"format":{"bookmark_icon":"https://pytorch.org/favicon.ico","copied_from_pointer":{"id":"28d7e8d7-3e46-4946-9da6-fcaa26a7b08c","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480081,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"28d7e8d7-3e46-4946-9da6-fcaa26a7b08c","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"cc3151af-cf36-4f6c-9f0c-09d218953ea0","version":13,"type":"text","properties":{"title":[["NVIDIA からは 一連の DL用途の profiler metrics をラップした DLProf がリリースされている（が Tensor Core Usage 等は nvprof からも取れる）"]]},"format":{"copied_from_pointer":{"id":"2b7af37c-12a8-4330-bebf-dedf511662a6","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480081,"last_edited_time":1610188680000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"2b7af37c-12a8-4330-bebf-dedf511662a6","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"913da990-8b51-4687-97a9-2c39157317ff","version":4,"type":"bookmark","properties":{"link":[["https://docs.nvidia.com/deeplearning/frameworks/dlprof-user-guide/"]],"title":[["DLProf User Guide :: NVIDIA Deep Learning Frameworks Documentation"]],"description":[["The Deep Learning Profiler (DLProf) User Guide provides instructions on using the DLProf tool to improve the performance of deep learning models. Deep Learning Profiler is a tool for profiling deep learning models to help data scientists understand and improve performance of their models visually via Tensorboard or by analyzing text reports."]]},"format":{"copied_from_pointer":{"id":"e3702217-d7b8-495f-8c87-9a1ecbba7d14","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480082,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"e3702217-d7b8-495f-8c87-9a1ecbba7d14","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"8292930b-0ce2-4d25-9111-e9c25aa2fc2c","version":4,"type":"sub_header","properties":{"title":[["Performance Tips (CUDA)"]]},"format":{"copied_from_pointer":{"id":"c6e39b72-d3a2-4143-b351-a4e6f5d5e544","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480090,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"c6e39b72-d3a2-4143-b351-a4e6f5d5e544","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"e6b9f62f-d3b6-4d03-9c76-bf1374a7368d","version":265,"type":"text","properties":{"title":[["以下に Performance Guide があるがはGPU玄人以外には難しいので最初は "],["CUDA C プロフェッショナルプログラミング",[["a","https://book.impress.co.jp/books/1115101001"]]],[" を読むと良い."]]},"created_time":1610188680000,"last_edited_time":1610188920000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"d3a0bfe4-9085-4452-9571-87d521cb198c","version":4,"type":"bookmark","properties":{"link":[["https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#performance-guidelines"]],"title":[["Programming Guide :: CUDA Toolkit Documentation"]],"description":[["Figure 2. GPU Computing Applications. CUDA is designed to support various languages and application programming interfaces. Figure 3. Automatic Scalability Note: A GPU is built around an array of Streaming Multiprocessors (SMs) (see Hardware Implementation for more details)."]]},"format":{"bookmark_cover":"https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/gpu-devotes-more-transistors-to-data-processing.png","copied_from_pointer":{"id":"890411d4-b932-41b7-8abc-1984b285601e","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480090,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"890411d4-b932-41b7-8abc-1984b285601e","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"0dcccb98-31cf-427f-9437-0623275450fa","version":109,"type":"text","properties":{"title":[["チューニングに対する基本的な考え方がまとまっている. "]]},"created_time":1610189126953,"last_edited_time":1610189100000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"29a3d252-b3d2-494c-af99-e3323cb74e3c","version":699,"type":"text","properties":{"title":[["プロファイル結果に応じて 1) 演算資源で律速している場合は GPU の SIMDで1命令で捌けないか、アルゴリズムの工夫で計算量が落ちないかを検討し、2) メモリ帯域で律速している場合 はメモリアクセス方法の改善や高速な（L1/sharedmem/register）メモリでの代替を検討する. "]]},"created_time":1610189460000,"last_edited_time":1610190120000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"5d4829aa-0215-4dc6-80a7-9bea70722b48","version":4,"type":"bookmark","properties":{"link":[["https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html"]],"title":[["Best Practices Guide :: CUDA Toolkit Documentation"]],"description":[["The programming guide to using the CUDA Toolkit to obtain the best performance from NVIDIA GPUs."]]},"format":{"bookmark_cover":"https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/graphics/l2-hitratio-before.png","copied_from_pointer":{"id":"ad239d6f-7594-4dc4-a6cb-0546f07164f1","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480091,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"ad239d6f-7594-4dc4-a6cb-0546f07164f1","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"1ee4ce53-46a7-4010-830c-9aaa3980f32a","version":97,"type":"text","properties":{"title":[["アーキテクチャごとの tuning guide は以下にまとまっている."]]},"created_time":1610189014371,"last_edited_time":1610188980000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"caec80d1-907c-4351-89cc-227ac68660f5","version":4,"type":"bookmark","properties":{"link":[["https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html#tuning-cuda-applications-for-ampere"]],"title":[["NVIDIA Ampere GPU Architecture Tuning Guide :: CUDA Toolkit Documentation"]],"description":[["The NVIDIA A100 GPU based on compute capability 8.0 increases the maximum capacity of the combined L1 cache, texture cache and shared memory to 192 KB, 50% larger than the L1 cache in NVIDIA V100 GPU. The combined L1 cache capacity for GPUs with compute capability 8.6 is 128 KB."]]},"format":{"copied_from_pointer":{"id":"43a41f21-d4d9-42c1-8af5-e0373f20ec42","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188480091,"last_edited_time":1610188440000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"43a41f21-d4d9-42c1-8af5-e0373f20ec42","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"b76132ba-ec1b-4bb0-8c33-592af4294985","version":222,"type":"text","properties":{"title":[["developer blog の pro tips は特定のアルゴリズムについて実践的なテクニックが紹介され、たまに更新されている"]]},"created_time":1610189035879,"last_edited_time":1610189640000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"1374fa69-2db0-4ef7-ad16-e0a3208fd634","version":14,"type":"bookmark","properties":{"link":[["https://developer.nvidia.com/blog/tag/pro-tip/"]],"title":[["Tag: Pro Tip | NVIDIA Developer Blog"]]},"format":{"bookmark_icon":"https://developer.nvidia.com/favicon.ico","bookmark_cover":"https://developer-blogs.nvidia.com/wp-content/uploads/2017/11/cuda_fortran-e1515644446394.jpg"},"created_time":1610189100000,"last_edited_time":1610189100000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"834d476a-7591-46bf-8fc5-153cab9303db","version":4,"type":"sub_header","properties":{"title":[["Performance Tips (Deep Learning)"]]},"format":{"copied_from_pointer":{"id":"c38cf890-fef6-4537-b620-dd512f6217fc","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188894666,"last_edited_time":1610188860000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"c38cf890-fef6-4537-b620-dd512f6217fc","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"fb3fec83-b400-4176-b75e-f08c68bbf37c","version":4,"type":"sub_sub_header","properties":{"title":[["Automated Mixed Precision Training (AMP)"]]},"format":{"copied_from_pointer":{"id":"d72ca172-749f-4405-8e16-629a327f1f88","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188894668,"last_edited_time":1610189340000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"d72ca172-749f-4405-8e16-629a327f1f88","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"c5907543-f168-4acc-9137-0aa401017866","version":4,"type":"text","properties":{"title":[["ECCV'20 での tutorial が現存する資料で最も優れている."]]},"format":{"copied_from_pointer":{"id":"db754799-ae09-40ec-b06d-e610cce21408","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188894668,"last_edited_time":1610188860000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"db754799-ae09-40ec-b06d-e610cce21408","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"42e43e6a-d9a5-409c-85b6-fc1faba2fc0c","version":4,"type":"bookmark","properties":{"link":[["https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/"]],"title":[["AMP tutorial"]],"description":[["This tutorial will describe techniques that utilize half-precision floating point representations to allow deep learning practitioners to accelerate the training of large deep networks while also reducing memory requirements."]]},"format":{"bookmark_icon":"https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/imgs/favicon.ico","bookmark_cover":"https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/imgs/WonminByeon.jpg","copied_from_pointer":{"id":"1499a1fb-3a4a-415c-a42f-0dec5e4b4202","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188894669,"last_edited_time":1610188860000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"1499a1fb-3a4a-415c-a42f-0dec5e4b4202","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"f99ba16c-db1e-4739-a9e9-1daf96ff2556","version":4,"type":"sub_sub_header","properties":{"title":[["Training Neural Networks with Tensor Cores"]]},"format":{"copied_from_pointer":{"id":"105ec520-3a95-4b2a-be9e-1168d0190d94","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188894670,"last_edited_time":1610188860000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"105ec520-3a95-4b2a-be9e-1168d0190d94","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"6d547906-7a84-4fd0-b833-5c31896554df","version":4,"type":"video","properties":{"source":[["https://www.youtube.com/watch?v=jF4-_ZK_tyc\u0026feature=youtu.be"]]},"format":{"block_width":854,"display_source":"https://www.youtube.com/embed/jF4-_ZK_tyc?feature=oembed","block_full_width":false,"block_page_width":true,"block_aspect_ratio":0.5620608899297423,"copied_from_pointer":{"id":"5eedc023-7e7a-468b-ab80-c3363211bb31","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"},"block_preserve_scale":true},"created_time":1610188894671,"last_edited_time":1610188860000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"5eedc023-7e7a-468b-ab80-c3363211bb31","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"ef577bea-018a-4b22-a956-9e0585918567","version":4,"type":"sub_sub_header","properties":{"title":[["PyTorch Performance Tips"]]},"format":{"copied_from_pointer":{"id":"87f3f80d-6e18-4b23-a711-2149a8525b49","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},"created_time":1610188894671,"last_edited_time":1610188860000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"87f3f80d-6e18-4b23-a711-2149a8525b49","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"ced16e4f-6225-4f01-b207-8e46cd677bc6","version":4,"type":"video","properties":{"source":[["https://www.youtube.com/watch?v=9mS1fIYj1So"]]},"format":{"block_width":854,"display_source":"https://www.youtube.com/embed/9mS1fIYj1So?feature=oembed","block_full_width":false,"block_page_width":true,"block_aspect_ratio":0.5620608899297423,"copied_from_pointer":{"id":"6ba18f52-8532-41b1-9a74-5803605b389f","table":"block","spaceId":"073d164e-c7ee-46f7-b28e-ac8326c08157"},"block_preserve_scale":true},"created_time":1610188894672,"last_edited_time":1610188860000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"copied_from":"6ba18f52-8532-41b1-9a74-5803605b389f","created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"a2ef0a48-707a-4418-b685-575be2cd5995","version":2,"type":"text","properties":{"title":[["https://developer.nvidia.com/blog/tag/pro-tip/",[["a","https://developer.nvidia.com/blog/tag/pro-tip/"]]]]},"created_time":1610189097216,"last_edited_time":1610189040000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"4b650e0e-ab02-4755-96ba-d703106ea9e6","version":28,"type":"sub_header","properties":{"title":[["TO BE CONTINUED ..."]]},"created_time":1610189330936,"last_edited_time":1610189880000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}},{"role":"editor","value":{"id":"513d5034-dc65-471b-924f-83bbe98175cd","version":18,"type":"text","properties":{"title":[["未定"]]},"created_time":1610189280000,"last_edited_time":1610189280000,"parent_id":"ceb89529-935e-4c2b-bf1f-044b7308524e","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","last_edited_by_table":"notion_user","last_edited_by_id":"8ed7f006-a5ae-48f7-974a-578ff0e45755","space_id":"073d164e-c7ee-46f7-b28e-ac8326c08157"}}]},"preview":false},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"performance-tips-for-gpu-computing"},"buildId":"EoTg-hnsU-NJ9bgKBhVqe","runtimeConfig":{},"isFallback":false,"gsp":true}</script><script nomodule="" src="/_next/static/chunks/polyfills-4f4acd756cef4fe6da1b.js"></script><script src="/_next/static/chunks/webpack-acbe2a1d0483950086ba.js" async=""></script><script src="/_next/static/chunks/framework.3e0dfad0cbf263c0c4a9.js" async=""></script><script src="/_next/static/chunks/commons.3f227e1c895e39cb7779.js" async=""></script><script src="/_next/static/chunks/main-deac83b1f9d78151fc4a.js" async=""></script><script src="/_next/static/chunks/pages/_app-6179aa4185a808d7a1de.js" async=""></script><script src="/_next/static/chunks/cb1608f2.7455795c198376a5d1d3.js" async=""></script><script src="/_next/static/chunks/6bd6ae6efdef6db205175312548a04e035b50d59.9002859aca81683f8631.js" async=""></script><script src="/_next/static/chunks/bfa37fcd0818edd0d3354ea585e5d4d4b3e87fa4.54a90d76d8498c0c7409.js" async=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-86baed40f497662539f5.js" async=""></script><script src="/_next/static/EoTg-hnsU-NJ9bgKBhVqe/_buildManifest.js" async=""></script><script src="/_next/static/EoTg-hnsU-NJ9bgKBhVqe/_ssgManifest.js" async=""></script></body></html>